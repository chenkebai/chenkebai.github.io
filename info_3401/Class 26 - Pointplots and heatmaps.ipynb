{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3401 â€“ Class 26: Pointplots and heatmaps\n",
    "\n",
    "[Brian C. Keegan, Ph.D.](http://brianckeegan.com/)  \n",
    "[Assistant Professor, Department of Information Science](https://www.colorado.edu/cmci/people/information-science/brian-c-keegan)  \n",
    "University of Colorado Boulder  \n",
    "\n",
    "Copyright and distributed under an [MIT License](https://opensource.org/licenses/MIT).\n",
    "\n",
    "## Learning Objectives\n",
    "* Working with spatial point data in GeoPandas\n",
    "* Visualizing spatial data as pointplots, sometimes in combination with choropleths\n",
    "* Visualizing spatial point data as heatmaps and kdeplots\n",
    "\n",
    "## Background\n",
    "\n",
    "This module will explore how to acquire, analyze, and visualize spatial data. I have adapted this content from the excellent course [Auotmating GIS processes](https://automating-gis-processes.github.io/site/index.html) course by [Vuokko Heikinheimo](https://researchportal.helsinki.fi/en/persons/vuokko-vilhelmiina-heikinheimo) and [Henrikki Tenkanen](https://www.ucl.ac.uk/geospatial-analytics/people/henrikki-tenkanen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries\n",
    "\n",
    "Load our usual libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# Visualization libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "import contextily, geoplot\n",
    "\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We're going to use the National Highway Traffic Safety Administration's databases on fatal highway accidents. [Data going back to 1976 is available](https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars), but we'll focus on data since 2012. There's also a detailed [user manual](https://www.nhtsa.gov/filebrowser/download/176821) describing these columns if you're interested: the data we're using correspdong to the \"ACCIDENT\" data files. The Appendix section at the end of the notebook details how this data was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fars_df = pd.read_csv('fars_2012-2018.csv')\n",
    "\n",
    "print(fars_df.shape)\n",
    "\n",
    "fars_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the US shapefile too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_gdf = gpd.read_file('us_states/tl_2019_us_state.shp')\n",
    "\n",
    "states_gdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally load the Colorado counties and convert the \"county\" name to title-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_counties_gdf = gpd.read_file('co_counties/co_counties.shp')\n",
    "\n",
    "co_counties_gdf['county'] = co_counties_gdf['county'].str.title()\n",
    "\n",
    "co_counties_gdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "We need to convert some of the columns in this data into more useful data types.\n",
    "\n",
    "First, take the \"YEAR\", \"MONTH\", \"DAY\", \"HOUR\", and \"MINUTE\" columns and use `pd.to_datetime` to combine them into a \"Timestamp\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, there are columns for \"LATITUDE\" (y-axis) and \"LONGITUD\" (x-axis). Use GeoPandas's [`points_from_xy`](https://geopandas.org/reference/geopandas.points_from_xy.html) function (also this tutorial [Creating a GeoDataFrame from a DataFrame with coordinate](https://geopandas.org/gallery/create_geopandas_from_pandas.html)). Convert these to a shapely Point geometry and convert the DataFrame into a GeoDataFrame by specifying both the geometry and the CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, there are more than 200,000 fatal car accidents in the six years of data across the entire U.S. Rename the \"State Name\" and \"County\" names to just \"State\" and \"County\" for simplicity. Then filter down to only accidents in Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Check the distribution of incidents by \"County\" and \"YEAR\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a groupby on the \"Timestamp\" column with a `Grouper` to plot the number of fatalities (\"FATALS\") per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some other methods like a rolling average to help clarify the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a pivot table with \"DAY_WEEK\" as columns, \"HOUR\" as index, \"FATALS\" as values, and 'sum' as an aggfunc. Visualize as a heatmap. Sunday is 1 and Saturday is 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point plot\n",
    "\n",
    "Visualize the individual incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize using the Colorado state boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize using a basemap. You may need to convert to another CRS like [EPSG:3857](https://epsg.io/3857) used by Google, OSM, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a density plot\n",
    "\n",
    "Use geoplot's [`kdeplot`](https://residentmario.github.io/geoplot/plot_references/plot_reference.html#kdeplot) ([tutorial](https://geopandas.org/gallery/plotting_with_geoplot.html)) to make a density plot of these points. Use geoplot's `webmap` to include a basemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to a choropleth\n",
    "\n",
    "We have done joins above and before in previous classes, but spatial data presents a new way to join data as well. A [spatial join](https://geopandas.org/mergingdata.html#spatial-joins) combines and merges data based on their respective geometries: is a Point within a Polygon for example? This is valuable if we want to take spatial data like accidents and aggregate to count the number of incidents per county. \n",
    "\n",
    "A spatial join allows us to merge the `co_counties_gdf` GeoDataFrame and the `co_fars_gdf` GeoDataFrame. Because the `co_fars_gdf` already has a column for \"County\" this feels a bit redundant, but because spatial joins are so powerful, I still want to cover how to do them and use the existing labels for verification.\n",
    "\n",
    "Inspect the `co_counties_gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the `co_fars_gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a spatial join do under the hood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the `sjoin` with `co_fars_gdf` on the left, `co_counties_gdf` on the right, using a \"left\" join, and an \"intersects\" operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are these errors? They all appear to be on county boundary lines/roads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group total fatalities by county and merge back into `co_counties_gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize county-level data as a choropleth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Read in the files and concatenate together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fars_accident_l = []\n",
    "\n",
    "for y in range(2012,2019):\n",
    "    _df = pd.read_csv('fars_{0}_accident.csv'.format(y))\n",
    "    fars_accident_l.append(_df)\n",
    "    \n",
    "fars_accident_df = pd.concat(fars_accident_l,ignore_index=True)\n",
    "fars_accident_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the GSA [Geographic Locator Codes](https://www.gsa.gov/reference/geographic-locator-codes-glcs-overview) for the states and counties used in the FARS data. These are at City-level, so make a DataFrame of just State and County codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glc_df = pd.read_excel('https://www.gsa.gov/cdnstatic/FRPP_GLC_-_United_StatesSep292020.xlsx')\n",
    "\n",
    "# Make title-cased\n",
    "glc_df['State Name'] = glc_df['State Name'].str.title()\n",
    "glc_df['City Name'] = glc_df['City Name'].str.title()\n",
    "glc_df['County Name'] = glc_df['County Name'].str.title()\n",
    "\n",
    "# Groupby state and county\n",
    "glc_state_county = glc_df.groupby(['State Code','County Code']).agg({'State Name':'first','County Name':'first'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in state and county codes with the FARS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_fars_df = pd.merge(left = fars_accident_df,\n",
    "         right = glc_state_county,\n",
    "         how = 'left',\n",
    "         left_on = ['STATE','COUNTY'],\n",
    "         right_on = ['State Code','County Code']\n",
    "        )\n",
    "\n",
    "labeled_fars_df.drop(columns=['timestamp','geometry','State Code','County Code'],inplace=True)\n",
    "\n",
    "labeled_fars_df.to_csv('fars_2012-2018.csv',index=False)\n",
    "\n",
    "labeled_fars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
