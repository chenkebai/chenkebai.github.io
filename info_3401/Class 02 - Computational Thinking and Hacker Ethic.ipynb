{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3402 â€“ Class 02: Computational Thinking and Hacker Ethic\n",
    "\n",
    "[Brian C. Keegan, Ph.D.](http://brianckeegan.com/)  \n",
    "[Assistant Professor, Department of Information Science](https://www.colorado.edu/cmci/people/information-science/brian-c-keegan)  \n",
    "University of Colorado Boulder  \n",
    "\n",
    "Copyright and distributed under an [MIT License](https://opensource.org/licenses/MIT).\n",
    "\n",
    "## Learning Objectives\n",
    "* Review computational thinking concepts, practices, and perspectives from INFO 1201, *etc*.\n",
    "* Downloading, launching, and interacting with Jupyter Notebooks\n",
    "* An exploratory data retrieval and analysis project\n",
    "\n",
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh no, a wall of text\n",
    "First a warning: we invest a **lot** of time in writing these documents with detailed narratives, examples, links to resources, etc. It is **really** important that you read, understand, and develop an expectation for what should happen before executing any cells. We often see students just auto-executing a whole notebook and wondering why things are not working.\n",
    "\n",
    "For example, do not execute the following cell or else it will print \"You should have read the instructions\" and prevent anything else from executing for a long time. If you did accidently run this cell, you can go to Kernel > Interrupt to stop it. Instead, convert the block of code below from \"Code\" type to a \"Raw NBConvert\" type from the drop-down menu to prevent it from being accidentally run.\n",
    "\n",
    "There are going to be many examples of cells you should exercise caution in running throughout the rest of the class. We will never intentionally include code that compromises the security of your computer but you should still be cautious about executing any code. \n",
    "\n",
    "Examples of cautious code blocks we will see in the remainder of our class include: installing a package and the code only needs to be run once, scraping data that could take minutes or hours to complete, or doing an analysis that might consume a lot of resources. \n",
    "\n",
    "*Please read the narratives and have some expectation for what each block of code should do before running it!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < 1e3:\n",
    "    print(\"You should have read the instructions!\")\n",
    "    i += 1\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational thinking _practices_\n",
    "\n",
    "Thinking back to examples of the *practices* of computational thinking (Brennan & Resnick 2012) from the slides:\n",
    "\n",
    "* **Experimenting and iterating**: developing, experimenting, and developing some more\n",
    "* **Testing and debugging**: making sure things work and solving problems when they arise\n",
    "* **Reusing and remixing**: building on existing projects or ideas and sharing your own work\n",
    "* **Abstracting and modularizing**: building something complex by putting together smaller parts\n",
    "\n",
    "Let's see what these practices look like through an exploratory data collection and analysis exercise.\n",
    "\n",
    "**Our goal**: Create a CSV file with the daily stock price since December 31, 2019 for each company in the [S&P 500 index](https://en.wikipedia.org/wiki/S%26P_500_Index).\n",
    "\n",
    "We are not expecting that you already be familiar with every piece of syntax in the rest of this example, so *do not stress* that you are already behind. We are going to learn much of this in the weeks to come! However, you should be able to follow the narrative and start to develop intuitions for how pieces work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find a list of companies and ticker symbols\n",
    "(**Reusing and remixing:** building on existing projects or ideas and sharing your own work)\n",
    "\n",
    "Googling around, I found a dataset hosted by [DataHub.io](https://datahub.io/): [S&P 500 Companies with Financial Information](https://datahub.io/core/s-and-p-500-companies#data). We don't need to register for an account or anything! But the data was created 2 years ago, so it may not be up-to-date.\n",
    "\n",
    "Option 1: Download the data to the same directory as this notebook and open it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AOS</td>\n",
       "      <td>A.O. Smith Corp</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABMD</td>\n",
       "      <td>ABIOMED Inc</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>Activision Blizzard</td>\n",
       "      <td>Communication Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>AAP</td>\n",
       "      <td>Advance Auto Parts</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>AMD</td>\n",
       "      <td>Advanced Micro Devices Inc</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                        Name                  Sector\n",
       "0    MMM                  3M Company             Industrials\n",
       "1    AOS             A.O. Smith Corp             Industrials\n",
       "2    ABT         Abbott Laboratories             Health Care\n",
       "3   ABBV                 AbbVie Inc.             Health Care\n",
       "4   ABMD                 ABIOMED Inc             Health Care\n",
       "5    ACN               Accenture plc  Information Technology\n",
       "6   ATVI         Activision Blizzard  Communication Services\n",
       "7   ADBE                  Adobe Inc.  Information Technology\n",
       "8    AAP          Advance Auto Parts  Consumer Discretionary\n",
       "9    AMD  Advanced Micro Devices Inc  Information Technology"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_companies_df = pd.read_csv('constituents_csv.csv')\n",
    "sp500_companies_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Read the data directly into the notebook from the web!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_companies_df = pd.read_csv('https://datahub.io/core/s-and-p-500-companies/r/constituents.csv')\n",
    "sp500_companies_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find a data service that provides historical stock prices for free\n",
    "(**Reusing and remixing:** building on existing projects or ideas and sharing your own work)\n",
    "\n",
    "Googling around, I found this blog post describing the \"[Best 5 free stock market APIs in 2020](https://towardsdatascience.com/best-5-free-stock-market-apis-in-2019-ad91dddec984)\" so let's start there! The top choice (and one I and [others](https://towardsdatascience.com/historical-stock-price-data-in-python-a0b6dc826836)) know from experience) relies on a library called [`yfinance`](https://github.com/ranaroussi/yfinance). I generally do not recommend installing libraries willy-nilly, but in this case, let's install a new library to let us access historical stock prices for free. \n",
    "\n",
    "We only need to install the library once (repeating it won't necessarily hurt) and we can do this from the command line or from within the notebook. I'm going install using the anaconda package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/31/8b374a12b90def92a4e27d0fc595fc43635f395984e36a075244d98bd265/yfinance-0.1.54.tar.gz\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\anaconda app\\lib\\site-packages (from yfinance) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\anaconda app\\lib\\site-packages (from yfinance) (1.16.5)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\anaconda app\\lib\\site-packages (from yfinance) (2.22.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/e7/e9f1661c28f7b87abfa08cb0e8f51dad2240a9f4f741f02ea839835e6d18/multitasking-0.0.9.tar.gz\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\anaconda app\\lib\\site-packages (from pandas>=0.24->yfinance) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\anaconda app\\lib\\site-packages (from pandas>=0.24->yfinance) (2.8.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda app\\lib\\site-packages (from requests>=2.20->yfinance) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda app\\lib\\site-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda app\\lib\\site-packages (from requests>=2.20->yfinance) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda app\\lib\\site-packages (from requests>=2.20->yfinance) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda app\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.12.0)\n",
      "Building wheels for collected packages: yfinance, multitasking\n",
      "  Building wheel for yfinance (setup.py): started\n",
      "  Building wheel for yfinance (setup.py): finished with status 'done'\n",
      "  Created wheel for yfinance: filename=yfinance-0.1.54-py2.py3-none-any.whl size=22414 sha256=de07e73c503488a91f499606cf1e0db9b96e401f7254e08cc4d625c43088922a\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\pip\\Cache\\wheels\\f9\\e3\\5b\\ec24dd2984b12d61e0abf26289746c2436a0e7844f26f2515c\n",
      "  Building wheel for multitasking (setup.py): started\n",
      "  Building wheel for multitasking (setup.py): finished with status 'done'\n",
      "  Created wheel for multitasking: filename=multitasking-0.0.9-cp37-none-any.whl size=8373 sha256=b89524bf440b3a0d58aca5332d31b45ee5f1445cfddf439ee0a06bed095aafab\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\pip\\Cache\\wheels\\37\\fa\\73\\d492849e319038eb4d986f5152e4b19ffb1bc0639da84d2677\n",
      "Successfully built yfinance multitasking\n",
      "Installing collected packages: multitasking, yfinance\n",
      "Successfully installed multitasking-0.0.9 yfinance-0.1.54\n"
     ]
    }
   ],
   "source": [
    "# Only need to run once\n",
    "! pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another alternative library we could use is [`pandas-datareader`](https://github.com/pydata/pandas-datareader) ([docs](https://pydata.github.io/pandas-datareader/)). This also doesn't come standard with Anaconda, so we will need to install the library as well from either the command line or from within the notebook. Again, you should only need to do this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run once\n",
    "! conda install -c anaconda pandas-datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7da9f55a5922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpdr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write some code to retrieve the historical price data for one company\n",
    "(**Experimenting and iterating**: developing, experimenting, and developing some more)\n",
    "\n",
    "When all else fails, read the documentation. The author of the `yfinance` package has a [nice blog post](https://aroussi.com/post/python-yahoo-finance) detailing how to use it!\n",
    "\n",
    "Ask for Apple's data from January 6 through August 17 of this year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "download() missing 1 required positional argument: 'tickers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f2102ec04246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m aapl_yf_df = yf.download(name='AAPL',\n\u001b[0m\u001b[0;32m      2\u001b[0m                          \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2019-12-31'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                          \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-08-24'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                          progress=False)\n",
      "\u001b[1;31mTypeError\u001b[0m: download() missing 1 required positional argument: 'tickers'"
     ]
    }
   ],
   "source": [
    "aapl_yf_df = yf.download(name='AAPL',\n",
    "                         start='2019-12-31',\n",
    "                         end='2020-08-24',\n",
    "                         progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the resulting data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_yf_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are [many data readers available](https://pydata.github.io/pandas-datareader/remote_data.html) with `pandas-datareader`, including (curiously) an undocumented 'yahoo' datareader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_pdr_df = pdr.DataReader(name='AAPL',\n",
    "                             data_source='yahoo',\n",
    "                             start='2019-12-31',\n",
    "                             end='2020-08-24')\n",
    "\n",
    "aapl_pdr_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Write a loop to repeat this code for all 500 companies\n",
    "(**Abstracting and modularizing**: building something complex by putting together smaller parts)\n",
    "\n",
    "The `yfinance` library has a built-in functionality that lets it make many requests in parallel. Let's  show off this fancy functionality first.\n",
    "\n",
    "First, get a list of all the companies' stock tickers from `sp500_companies_df` and turn it into a list using the [`.tolist()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.tolist.html) method that converts the data from a pandas Series data type (which non-pandas functions like `yfinance` may not recognize) into a basic list data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_symbol_list = sp500_companies_df['Symbol'].tolist()\n",
    "sp500_symbol_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check it has 500 symbols. 505? Interesting, someone should get to the bottom of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp500_symbol_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the list of companies to the `download` function specific to the `yfinance` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = yf.download(sp500_symbol_list,interval='1d',start='2019-12-31',end='2020-08-24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This special functionality that takes a list of multiple symbols (in this case 505) is special and not what you would do 99% of the time: take each symbol, use the function to get its data, store this data in some structure, and move on to the next symbol. This takes much longer that the previous (special) approach but I've illustrated it below since it's much closer to how this works in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary where we will store results\n",
    "all_data_dict = {}\n",
    "\n",
    "# Loop through each symbol \n",
    "for i,symbol in enumerate(sp500_symbol_list):\n",
    "    \n",
    "    # Get the data for that symbol, sil\n",
    "    _df = yf.download(symbol,interval='1d',start='2019-12-31',end='2020-08-24',progress=False)\n",
    "    \n",
    "    # Could use the pandas-datareader function instead\n",
    "    #aapl_pdr_df = pdr.DataReader(symbol,data_source='yahoo',start='2019-12-31',end='2020-08-17')\n",
    "    \n",
    "    # Store the data in the dictionary\n",
    "    all_data_dict[symbol] = _df\n",
    "    \n",
    "    # It's common courtesy to wait a bit in between each request to avoid overwhelming a system\n",
    "    time.sleep(.1)\n",
    "    \n",
    "    # Print out where we are in the process, every 50th symbol\n",
    "    if i%50 == 0:\n",
    "        print(i,symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Write code to combine all this data together into one structure\n",
    "(**Testing and debugging**: making sure things work and solving problems when they arise)\n",
    "\n",
    "Using the magic `yfinance.download` function, we have a giant DataFrame with a [multi-index](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see all those column values. We can access them with the `.columns.levels` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.columns.levels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the \"Adj Close\" values by treating it like a dictionary. The rows are days and the columns are the company symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['Adj Close'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we used the loop strategy, then the data is parked inside the `all_data_dict`. We can use the [`concat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) function in pandas to combine them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat(all_data_dict)\n",
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a multi-index on the index with both symbol and date and then the values for that stock on each day as columns. I like the simpler dates as rows and symbols as columns approach from above. We can access a single column of `concat_df` with bracket notation and then [`unstack`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unstack.html?highlight=unstack#pandas.Series.unstack) the multi-indexed Series into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjclose_concat_s = concat_df['Adj Close']\n",
    "\n",
    "# Inspect\n",
    "adjclose_concat_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstack the multi-indexed series into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjclose_concat_df = adjclose_concat_s.unstack(0)\n",
    "\n",
    "# Inspect\n",
    "adjclose_concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Write to disk\n",
    "(**Reusing and remixing**: building on existing projects or ideas and sharing your own work)\n",
    "\n",
    "We have done all this hard work, now save the results to disk so you can just load them instead of crawling the data again as a CSV file. This file you could then give to someone else who could open in a spreadsheet program like Excel. Character encoding errors are a huge pain to deal with, so I also make sure to explicitly encode my data to disk with the common UTF-8 standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('sp500_constituents_2020.csv',encoding='ut8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Do some exploratory analyses on all this data\n",
    "(**Experimenting and iterating**: developing, experimenting, and developing some more)\n",
    "\n",
    "There's a lot of variance in the prices of the S\\&P 500 constituents: some stocks are only \\\\$10 per share while others are in excess of \\\\$1,000 per share. We could explore these values with a [histogram](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#histograms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the prices  on December 31 by accessing the row using the .loc\n",
    "dec31_prices = adjclose_concat_df.loc['2019-12-31']\n",
    "\n",
    "# Make the histogram on these data\n",
    "ax = dec31_prices.hist(bins=50)\n",
    "\n",
    "# Always label your axes!\n",
    "ax.set_xlabel('Adjusted Close')\n",
    "ax.set_ylabel('Number of symbols')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these low and high values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec31_prices.sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec31_prices.sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of a few outlier values skews the histogram. This large range of values is perfect to illustrate on a logarithmic scale, which calls for [logarithmic bins](https://stackoverflow.com/a/6856155/1574687)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = adjclose_concat_df.loc['2019-12-31'].hist(bins=np.logspace(0,4,50))\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim((0,60))\n",
    "ax.set_xlabel('Adjusted close')\n",
    "ax.set_ylabel('Number of companies')\n",
    "\n",
    "# https://matplotlib.org/api/ticker_api.html#matplotlib.ticker.StrMethodFormatter\n",
    "ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('${x:,.0f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The COVID-19 pandemic and resulting shutdowns caused a historic crash and recovery in the stock market in 2020. Let's visualize the daily prices of each constituent stock over time. Given that there is so much variance in the prices of these stocks, let's normalize their prices to 1 on December 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by dividing the values by their Dec 31 values\n",
    "norm_adjclose_concat_df = adjclose_concat_df.div(adjclose_concat_df.loc['2019-12-31'])\n",
    "\n",
    "# The data doesn't include weekends, holidays, and other days when the markets are closed\n",
    "# Reindex the data to include all dates since the 31st to make a cleaner axis\n",
    "norm_adjclose_concat_df = norm_adjclose_concat_df.reindex(pd.date_range('2019-12-31','2020-08-17'))\n",
    "\n",
    "# Plot the data\n",
    "ax = norm_adjclose_concat_df.plot(c='k',alpha=.25,legend=False,figsize=(10,5))\n",
    "\n",
    "# Include a consistent range of y-values\n",
    "ax.set_ylim((0,2.5))\n",
    "\n",
    "# Include a yellow line with the average\n",
    "norm_adjclose_concat_df.mean(axis=1).plot(ax=ax,c='y',lw=5)\n",
    "\n",
    "# Include a red dashed line at 1 as a baseline\n",
    "ax.axhline(y=1,ls='--',c='r')\n",
    "\n",
    "# Save the picture\n",
    "plt.tight_layout()\n",
    "plt.savefig('sp500_prices_normalized_2020.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the crash in March when stock prices fell by almost 50% since the start of the year and the sustained rise since then as stimulus measures injected cash and liquidity into the economy. The gaps in the data are the days when the market was closed.\n",
    "\n",
    "The stock market has (surprisingly, to me) almost recovered all its losses. Some stocks have performed amazingly well, nearly doubling in value since January, while others remain really depressed and only a quarter of their original value.\n",
    "\n",
    "We can compute the ratio between the most recent and the December 31 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_s = adjclose_concat_df.loc['2020-08-13']/adjclose_concat_df.loc['2019-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some of the higher and lowest ratios? Travel companies like Norwegian Cruise Lines (NCLH), Carnival Cruise Lines (CCL), and United Airlines (UAL); oil extractors like Occidental Petroleum (OXY); and luxury brand owner Coty (COTY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_s.sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the best performers are e-commerce firms like Paypal (PYPL), chip makers like NVIDIA (NVDA), and pharmaceurical and medical device makers like Abiomed (ABMD), West Pharmaceuticals (WST), and Dexcom (DXCM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_s.dropna().sort_values().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize as a histogram to reveal that most companies are near their values at the start of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ratio_s.hist(bins=50)\n",
    "ax.set_xlim((0,2))\n",
    "ax.axvline(1,c='r',ls='--')\n",
    "ax.set_xlabel('Price ratio')\n",
    "ax.set_ylabel('Number of companies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sp500_price_ratio_2020.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational thinking _perspectives_\n",
    "\n",
    "Thinking back to examples of the *perspectives* of computational thinking (Brennan & Resnick 2012) from the slides:\n",
    "\n",
    "* **Expressing**: computation as a medium for creative and critical expression\n",
    "* **Connecting**: computation as a tool for of creating for and interacting with others\n",
    "* **Questioning**: computation as a tool for investigating how the world works\n",
    "\n",
    "What could we do next now that we have this data and these exploratory findings? \n",
    "\n",
    "What are other ways that we could use this notebook, these data, and these results to pursue creative or critical questions (**expressing**)? \n",
    "\n",
    "How could we share these findings, who else could be interested in using these data and results, and how could we get it to them (**connecting**)?\n",
    "\n",
    "What do these data and results reveal about the disconnects between reactions of the stock market and the experiences of most Americans? What other kinds of data or analyses would we need to explore this (**questioning**)? \n",
    "\n",
    "Let's talk about these in lecture together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
